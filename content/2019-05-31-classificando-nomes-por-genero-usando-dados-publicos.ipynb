{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Classificando Nomes por Gênero Usando Dados Públicos\n",
    "- Slug: classificando-nomes-por-genero-usando-dados-publicos\n",
    "- Date: 2019-05-31 15:10\n",
    "- Category: datasets\n",
    "- Tags: python, data science\n",
    "- Author: turicas\n",
    "- Summary: Muitos datasets que possuem dados sobre pessoas não possuem a informação de gênero correspondente, dificultando projetos de dados onde o recorte por gênero é necessário. Nesse artigo vamos aprender a utilizar um dataset do Brasil.IO para fazer essa classificação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitos *datasets* que possuem dados sobre pessoas não possuem a informação de gênero correspondente, como o *dataset* de candidatura das eleições para o ano de 1.996 divulgado pelo [Tribunal Superior Eleitoral](http://www.tse.jus.br/) ([veja esse *dataset* no Brasil.IO](https://brasil.io/dataset/eleicoes-brasil/candidatos?ano_eleicao=1996)) e o *dataset* de salários dos magistrados divulgado pelo [Conselho Nacional de Justiça](http://cnj.jus.br/) ([veja esse *dataset* no Brasil.IO](https://brasil.io/dataset/salarios-magistrados/contracheque)). A falta dessa informação dificulta projetos de dados onde o recorte por gênero é necessário, como é o caso [desse vídeo](https://www.youtube.com/watch?v=7yQ8U2tFFq4) que ajudei a construir, onde classificamos por gênero todos os nomes de ruas, avenidas e praças do Brasil. \n",
    "\n",
    "Nesse artigo vamos aprender a utilizar os dados de [nomes brasileiros do Censo 2010 do IBGE](https://censo2010.ibge.gov.br/nomes/#/search) que estão [disponíveis no Brasil.IO](https://brasil.io/dataset/genero-nomes) para fazer essa classificação, utilizando como base mais de 100 mil nomes e a [linguagem Python](https://www.python.org/)! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando as dependências\n",
    "\n",
    "Antes de iniciar o código criaremos um ambiente virtual (virtualenv) utilizando a versão 3.7 do Python (vou utilizar o\n",
    "[pyenv](https://github.com/pyenv/pyenv) e [pyenv-virtualenv](https://github.com/pyenv/pyenv-virtualenv) para isso, mas fique à vontade para utilizar outras ferramentas em seu ambiente). Para esse projeto utilizaremos apenas as bibliotecas da [*standard library* do Python](https://docs.python.org/3/library/), ou seja, não precisaremos instalar bibliotecas externas.\n",
    " \n",
    "```bash\n",
    "pyenv virtualenv 3.7.3 classificador-genero\n",
    "pyenv activate classificador-genero\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo o Dataset\n",
    "\n",
    "A [tabela nomes do *dataset* genero-nomes](https://brasil.io/dataset/genero-nomes/nomes) possui a lista de todos os nomes encontrados no Censo 2010, contendo a frequência desse nome para os gêneros masculino e feminino, a classificação baseada nessa frequência (o gênero que tiver frequência maior) e a probabilidade da classificação ser verdadeira (frequência do gênero que aparece mais dividida pela frequência total do nome), como podemos ver na seguinte tabela:\n",
    "\n",
    "![Tabela de gênero dos nomes]({static}/images/2019-05-31-tabela-genero-nomes.png)\n",
    "\n",
    "Para o nome ABADIAS, por exemplo, existem 45 pessoas do gênero feminimo e 156 do masculino, então o nome é classificado com o gênero `M` (masculino) com uma probabilidade de 78% (`156 / (156 + 45)`).\n",
    "\n",
    "Repare também que os nomes contidos nesse *dataset* estão todos em letras maiúsculas e sem acentos, então precisaremos criar uma função para transformar o nome que queremos classificar (exemplo: `Álvaro`) para esse formato. Para isso, vamos utilizar a função `normalize` do módulo [unicodedata](https://docs.python.org/3/library/unicodedata.html) para separar os acentos das letras e ignorar os erros ao converter para o *encoding* ASCII, que eliminará todos os símbolos que não queremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALVARO\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def encode(name):\n",
    "    ascii_name = normalize(\"NFKD\", name).encode(\"ascii\", errors=\"ignore\").decode(\"ascii\")\n",
    "    return ascii_name.upper()\n",
    "\n",
    "print(encode(\"Álvaro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possíveis Abordagens\n",
    "\n",
    "Para esse projeto vamos fazer um **classificador simples**, sem a utilização de técnicas de aprendizado de máquina, ou seja, ele será capaz de classificar apenas os nomes já disponíveis em nosso dataset. Em próximos artigos mostraremos como criar outros tipos de classificadores.\n",
    "\n",
    "Para resolver essa questão, temos duas abordagens possíveis:\n",
    "- Utilizar a [API do Brasil.IO](https://brasil.io/api/datasets), fazendo uma requisição a cada nome a ser classificado; e\n",
    "- Baixar o dataset completo e utilizar os dados localmente.\n",
    "\n",
    "Cada uma das abordagens tem vantagens e desvantagens, que veremos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 1: Utilizando a API\n",
    "\n",
    "Vantagens:\n",
    "\n",
    "- Não precisaremos baixar o dataset completo\n",
    "- Utiliza pouca memória\n",
    "\n",
    "Desvantagens:\n",
    "\n",
    "- Classificação lenta (uma requisição HTTP por classificação)\n",
    "\n",
    "Vamos criar uma função que recebe o nome, faz a requisição HTTP usando a [urllib](https://docs.python.org/3/library/urllib.html), lê os dados com a [json](https://docs.python.org/3/library/json.html) e retorna o resultado encontrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def classify_api(name):\n",
    "    encoded_name = encode(name)\n",
    "    url = \"https://brasil.io/api/dataset/genero-nomes/nomes/data?first_name=\" + encoded_name\n",
    "    response = urlopen(url)\n",
    "    json_response = json.loads(response.read())\n",
    "    return json_response[\"results\"][0][\"classification\"]\n",
    "\n",
    "print(classify_api(\"Álvaro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica como sugestão de exercício melhorar a função acima, adicionando tratamento de erros caso o nome não seja encontrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 2: Baixando os dados\n",
    "\n",
    "Vantagens:\n",
    "\n",
    "- Classificação rápida (acesso à chave de um dicionário)\n",
    "\n",
    "Desvantagens:\n",
    "\n",
    "- Precisaremos baixar o dataset completo\n",
    "- Utiliza mais memória\n",
    "\n",
    "Vamos utilizar o `wget` no terminal para baixar a tabela `nomes` completa:\n",
    "\n",
    "```bash\n",
    "wget https://data.brasil.io/dataset/genero-nomes/nomes.csv.gz\n",
    "```\n",
    "\n",
    "Agora, vamos ler o arquivo CSV e criar um dicionário em que cada chave será um nome e o valor será a classificação correspondente, para isso utilizaremos os módulos [gzip](https://docs.python.org/3/library/gzip.html) (para descompactar o arquivo), [io](https://docs.python.org/3/library/io.html) (para decodificar o conteúdo do arquivo descompactado) e [csv](https://docs.python.org/3/library/csv.html) (para ler o arquivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicionário criado com 100787 nomes.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import io\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    fobj = io.TextIOWrapper(gzip.open(\"nomes.csv.gz\"), encoding=\"utf-8\")\n",
    "    csv_reader = csv.DictReader(fobj)\n",
    "    data = {\n",
    "        row[\"first_name\"]: row[\"classification\"]\n",
    "        for row in csv_reader\n",
    "    }\n",
    "    fobj.close()\n",
    "    return data\n",
    "\n",
    "name_data = load_data()\n",
    "\n",
    "print(f\"Dicionário criado com {len(name_data)} nomes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a variável `name_data` definida podemos criar a função de classificação facilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "def classify_download(name):\n",
    "    encoded_name = encode(name)\n",
    "    return name_data[encoded_name]\n",
    "\n",
    "print(classify_download(\"Álvaro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando as Soluções\n",
    "\n",
    "A primeira solução não exige tempo de *download* inicial, nem de carragamento dos dados, porém é bem mais lenta - cada classificação demora em torno de 1 segundo (esse valor pode variar, dependendo de sua conexão à Internet e à carga nos servidores do Brasil.IO):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 s ± 309 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit classify_api(\"Álvaro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já a segunda solução requer o *download* (uma única vez) de um arquivo de 1,9MB e mais um tempo inicial de quase meio segundo para carregar os dados em memória, porém é 1 milhão de vezes mais rápida - cada classificação demora em torno de 1 microssegundo (esse valor pode variar dependendo do processador e velocidades do disco e da memória):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 ms ± 37.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.02 µs ± 33.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit load_data()\n",
    "%timeit classify_download(\"Álvaro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Podemos utilizar dados públicos para enriquecer diversos outros *datasets*, possibilitando análises que antes não seriam possíveis. A utilização da API do Brasil.IO é bem simples e pode ser útil em casos de poucas consultas, mas quando a quantidade de consultas aumenta, o ideal é baixar os dados e trabalhar com eles localmente.\n",
    "\n",
    "Curtiu o artigo? Se você acha o trabalho que desenvolvemos importante, considere\n",
    "**[fazer uma doação](https://brasil.io/doe)** ou [colaborar de outras formas](https://brasil.io/colabore). ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
